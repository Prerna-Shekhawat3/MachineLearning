
# Linear Regression #

It is a supervised Learning Algorithm. The main obbjective of linear Regression to find a bit fit line that fits the data. Linear regression is a statistical method that is used to model the relationship between a dependent variable and one or more independent variables. The dependent variable is the variable that you are trying to predict, and the independent variables are the variables that you are using to predict the dependent variable. 

Types of linear regression
There are two main types of linear regression: 
* Simple linear regression* 
* Multiple linear regression* 

* **How it works**

Linear regression models the relationship between the dependent variable and the independent variables using a linear equation. The linear equation is of the form:

```
y = mx + b
```

where:
* y is the dependent variable
* m is the slope of the line
* b is the y-intercept
* x is the independent variable

The slope of the line, m, tells you how much the dependent variable changes for every unit change in the independent variable. The y-intercept, b, tells you the value of the dependent variable when the independent variable is equal to 0.

* **How to use it**

To use linear regression, you first need to collect data on the dependent variable and the independent variables. Once you have collected the data, you can use a statistical software package to fit a linear regression model to the data. The software package will calculate the values of m and b, and it will also provide you with a number of other statistics, such as the R2 score.

* **Multiple Linear regression**
  
```
y = b0 + b1x1 + b2x2 + ... + bn*xn
```

where:

* **y is the dependent variable* **
* **b0 is the y-intercept* **
* **b1, b2, ..., bn are the regression coefficients* **
* **x1, x2, ..., xn are the independent variables* **
 
The multiple linear regression equation is a linear equation that models the relationship between the dependent variable and the independent variables. The equation is made up of a constant term, b0, and a series of terms that multiply the independent variables by the regression coefficients, b1, b2, ..., bn.


Assumptions of linear regression
There are a number of assumptions that must be met in order for linear regression to be a valid statistical tool. These assumptions include:

* The independent and depandent features should have a Linear Relationship.
* There should be no multicollinearity between depandent features.
* Normality of Residual.
* homoscedasticity
* No correlation between error.
  
Limitations of linear regression
Linear regression is a powerful tool, but it has some limitations. These limitations include:

* It assumes that the relationship between the dependent variable and the independent variables is linear.
* It is sensitive to outliers.
* It can be difficult to interpret the results of a linear regression model.
  
Optimizers of Linear Regression:

* Ridge regression: This is a type of regression that adds a penalty to the model's complexity. This helps to prevent overfitting.
* Lasso regression: This is a type of regression that adds a penalty to the model's coefficients. This helps to select the most important independent variables.

  
* **Conclusion**

Linear regression is a powerful statistical tool that can be used to model the relationship between a dependent variable and one or more independent variables. It is a relatively easy tool to use, and it can be used to analyze a wide variety of data.
